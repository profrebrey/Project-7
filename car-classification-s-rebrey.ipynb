{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Car classification\n![](http://img1.joyreactor.cc/pics/post/автопром-ваз-лимузин-ватермарк-351083.jpeg)\n\n### Основная идея - берем предобученую на imagenet сеть Xception и дообучаем под нашу задачу.\n\nУдачи и Поехали!","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-05T17:19:39.330408Z","iopub.execute_input":"2021-08-05T17:19:39.330868Z","iopub.status.idle":"2021-08-05T17:19:40.213431Z","shell.execute_reply.started":"2021-08-05T17:19:39.330833Z","shell.execute_reply":"2021-08-05T17:19:40.211765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/mjkvaak/ImageDataAugmentor\n!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:19:40.216251Z","iopub.execute_input":"2021-08-05T17:19:40.216942Z","iopub.status.idle":"2021-08-05T17:19:59.403818Z","shell.execute_reply.started":"2021-08-05T17:19:40.216878Z","shell.execute_reply":"2021-08-05T17:19:59.402481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\n\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\nimport tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom tensorflow.keras.callbacks import (Callback, EarlyStopping,\n                                        LearningRateScheduler, ModelCheckpoint)\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations as A\nimport efficientnet.tfkeras as efn\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-08-05T17:19:59.409666Z","iopub.execute_input":"2021-08-05T17:19:59.410005Z","iopub.status.idle":"2021-08-05T17:19:59.46049Z","shell.execute_reply.started":"2021-08-05T17:19:59.409969Z","shell.execute_reply":"2021-08-05T17:19:59.458774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Работаем уже с Tensorflow 2.4.1","metadata":{}},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-05T17:19:59.46371Z","iopub.execute_input":"2021-08-05T17:19:59.464664Z","iopub.status.idle":"2021-08-05T17:20:01.633333Z","shell.execute_reply.started":"2021-08-05T17:19:59.464614Z","shell.execute_reply":"2021-08-05T17:20:01.631756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.638661Z","iopub.execute_input":"2021-08-05T17:20:01.639017Z","iopub.status.idle":"2021-08-05T17:20:01.653448Z","shell.execute_reply.started":"2021-08-05T17:20:01.638981Z","shell.execute_reply":"2021-08-05T17:20:01.652075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# В сетап выношу основные настройки, так удобней их перебирать в дальнейшем\n\nEPOCHS               = 12 #эпох на обучение\nBATCH_SIZE           = 64 #меньшаем batch если сеть большая, иначе не поместится в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 #сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10 # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nOUR_PATH='./car'\nPATH = \"/kaggle/working/car/\"\n\n\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.658027Z","iopub.execute_input":"2021-08-05T17:20:01.658347Z","iopub.status.idle":"2021-08-05T17:20:01.712879Z","shell.execute_reply.started":"2021-08-05T17:20:01.658316Z","shell.execute_reply":"2021-08-05T17:20:01.709131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA / Анализ данных","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.71407Z","iopub.status.idle":"2021-08-05T17:20:01.71469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.716137Z","iopub.status.idle":"2021-08-05T17:20:01.71697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.Category.value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.718683Z","iopub.status.idle":"2021-08-05T17:20:01.719627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Распределение классов довольно равномерное, не требует доработок","metadata":{}},{"cell_type":"code","source":"print('Распаковываем картинки')\n# Распакуем картинки\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.721159Z","iopub.status.idle":"2021-08-05T17:20:01.722036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-05T17:20:01.723544Z","iopub.status.idle":"2021-08-05T17:20:01.724525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.726116Z","iopub.status.idle":"2021-08-05T17:20:01.727139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Уже догадался что означают классы?\n### Тогда перейдем к подготовке данных...\n![](http://admem.ru/content/images/1391000424.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"### Data augmentation","metadata":{}},{"cell_type":"code","source":"# Аугментация данных очень важна когда у нас не большой датасет (как в нашем случае)\n\nAUGMENTATIONS = A.Compose([\n    A.RandomBrightness(limit=0.2, p=0.5),\n    A.HueSaturationValue(p=0.5),\n    A.GaussianBlur(p=0.05),\n    A.RGBShift(p=0.5),\n    A.Rotate(limit=30,\n             interpolation=1,\n             border_mode=4,\n             value=None,\n             mask_value=None,\n             always_apply=False,\n             p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.0625,\n                       scale_limit=0.01,\n                       interpolation=1,\n                       border_mode=4,\n                       rotate_limit=20,\n                       p=.75),\n    A.OneOf([\n        A.CenterCrop(height=224, width=200),\n        A.CenterCrop(height=200, width=224)],\n        p=0.5),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)],\n        p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    A.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen=ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUGMENTATIONS,\n        validation_split=VAL_SPLIT\n        )\n\n\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\n#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.728769Z","iopub.status.idle":"2021-08-05T17:20:01.729693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### datagen","metadata":{}},{"cell_type":"code","source":"# \"Заворачиваем\" наши данные в generator\n\ntrain_generator= train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator=train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe(\n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# кстати, ты заметил, что для сабмишена мы используем другой источник для генератора flow_from_dataframe? \n# Как ты думаешь, почему?","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.73135Z","iopub.status.idle":"2021-08-05T17:20:01.732242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Посмотрим, как выглядят изображения после аугментации\n\nfrom skimage import io\n\ndef imshow(image_RGB):\n  io.imshow(image_RGB)\n  io.show()\n\nx,y = train_generator.next() # вызываем трейн-генератор\nprint('Пример картинок из train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.73396Z","iopub.status.idle":"2021-08-05T17:20:01.734866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y = test_generator.next() \nprint('Пример картинок из test_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.736533Z","iopub.status.idle":"2021-08-05T17:20:01.737348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def callbacks_func():\n    earlystopping = EarlyStopping(monitor='accuracy',patience=4, verbose=1)\n    checkpoint = ModelCheckpoint(f'{MODEL}_best.hdf5' , monitor = 'val_acc' , verbose = 1  , mode = 'max') \n    callbacks_list = [checkpoint, earlystop]\n    return callbacks_list\n\ncallbacks = callbacks_func()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.738958Z","iopub.status.idle":"2021-08-05T17:20:01.739816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"### подгружаем предобученую сеть Xception","metadata":{}},{"cell_type":"code","source":"# Кстати Попробуй еще другие архитектуры сетей...\nbase_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.741949Z","iopub.status.idle":"2021-08-05T17:20:01.742782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-05T17:20:01.744254Z","iopub.status.idle":"2021-08-05T17:20:01.745152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую \"голову\"\n# Тут тоже можно поиграться, попробуй добавить Batch Normalization например.\n\nfor layer in base_model.layers [:50]:\n    layer.trainable = False\n    \nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.25)(x)\nx = Dense(256, activation='relu')(x) #моя добавка\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# ВСТАВКА fine-tuning только для последних слоев\nfor layer in base_model.layers[-30:]:\n    # батч норм должен настраивать свои параметры для новых данных! а иначе фиксируем слой!\n    if not isinstance(layer, BatchNormalization):\n        layer.trainable = False\n\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n \nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.747024Z","iopub.status.idle":"2021-08-05T17:20:01.747896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-05T17:20:01.74933Z","iopub.status.idle":"2021-08-05T17:20:01.750317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit","metadata":{}},{"cell_type":"code","source":"# Рекомендую добавть еще функции из https://keras.io/callbacks/\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\n# Для про - попробуй добавить разные техники управления Learning Rate\n# Например:\n# https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6\n# http://teleported.in/posts/cyclic-learning-rate/","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.75191Z","iopub.status.idle":"2021-08-05T17:20:01.752736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\n# попробуй применить transfer learning с fine-tuning\n# Сначала замораживаем все слои кроме новой \"головы\"\n# Потом, когда мы научили последние слои (голову) под новую задачу, можно разморозить все слои и пройтись маленьким лернинг рейтом","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.754514Z","iopub.status.idle":"2021-08-05T17:20:01.755254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('../working/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.756669Z","iopub.status.idle":"2021-08-05T17:20:01.757551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-05T17:20:01.75891Z","iopub.status.idle":"2021-08-05T17:20:01.759777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-05T17:20:01.761412Z","iopub.status.idle":"2021-08-05T17:20:01.762305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"test_sub_generator.samples","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.763774Z","iopub.status.idle":"2021-08-05T17:20:01.764675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.766181Z","iopub.status.idle":"2021-08-05T17:20:01.767016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# Для Про - попробуй добавить TTA\n# https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.768573Z","iopub.status.idle":"2021-08-05T17:20:01.769417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.770945Z","iopub.status.idle":"2021-08-05T17:20:01.771763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-05T17:20:01.773557Z","iopub.status.idle":"2021-08-05T17:20:01.774356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Интересно, к какому классу модель отнесет вот этот авто:\n![](http://kvu.su/upload/iblock/e3a/e3a32ed064fd71e4ce99b7f57d2de745.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Что можно сделать, чтоб улучшить результат:\n* Подобрать LR, optimizer, loss\n* Добавить аугментацию - done\n* Поиграться с архитектурой\n* Подобрать другие переменные (размер картинки, батч и тп)\n* Добавить политику обучения\n* Добавить TTA\n* Найти и обучиться на других внешних данных\n* Построить ансамбль из разных архитектур\n\n### Удачи в соревновании!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сколько слоев\nprint(len(base_model.layers))","metadata":{"execution":{"iopub.status.busy":"2021-08-05T17:20:01.775835Z","iopub.status.idle":"2021-08-05T17:20:01.776697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}